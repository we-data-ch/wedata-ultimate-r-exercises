{
  "hash": "46169698e1ccd218703cb6814c6a3ed9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Tidyverse II: Intermediate Data Wrangling\"\nauthor: \"David Munoz Tord\"\ndescription: \"Deep dive into joins, pivots, string ops and more with the tidyverse\"\nengine: knitr\ndate: \"2025-05-11\"\nformat: live-html\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Course Overview\n\nWelcome to Tidyverse II! In this intermediate course, we'll build upon your existing Tidyverse knowledge to tackle more complex data manipulation tasks. You'll learn how to effectively combine, reshape, and clean diverse datasets, mastering techniques essential for real-world data analysis.\n\nWe will cover:\n\n1.  **Recap & Setup**: A quick refresher on Tidyverse fundamentals and setting up our environment.\n2.  **Joins**: Combining data from multiple tables.\n3.  **Pivoting & Reshaping**: Transforming data between wide and long formats.\n4.  **String Operations**: Working with textual data using {stringr}.\n5.  **Date-Time Operations**: Handling dates and times with {lubridate}. (Coming soon!)\n6.  **Advanced Graphics**: Taking {ggplot2} skills to the next level. (Coming soon!)\n7.  **Factor Operations**: Managing categorical data with {forcats}. (Coming soon!)\n8.  **Capstone Project**: Applying all learned skills to a comprehensive project. (Coming soon!)\n\nLet's begin!\n\n---\n\n## Lesson 1: Recap & Setup\n\nBefore diving into new material, let's briefly revisit the core principles of the Tidyverse and ensure our R environment is ready.\n\nThe **Tidyverse** is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. Key packages include:\n\n*   **{dplyr}**: For data manipulation (filtering, arranging, selecting, mutating, summarizing).\n*   **{ggplot2}**: For creating elegant and informative data visualizations.\n*   **{tidyr}**: For tidying data (making it easy to work with).\n*   **{readr}**: For reading rectangular data files (like CSVs).\n*   **{purrr}**: For functional programming, enhancing your R toolkit.\n*   **{tibble}**: For modern, user-friendly data frames.\n*   **{stringr}**: For working with strings and regular expressions.\n*   **{forcats}**: For handling categorical variables (factors).\n\nA central concept is the **pipe operator `%>%`** (or the base R pipe `|>` from R 4.1+). It allows you to chain operations together in a readable and intuitive way, passing the result of one function as the first argument to the next.\n\nFor this course, we'll primarily use RStudio or a similar R environment. Ensure you have the `tidyverse` package installed. If not, you can install it with `install.packages(\"tidyverse\")`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the entire tidyverse\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\n# Example: Using the pipe with dplyr\n# Let's inspect the built-in starwars dataset\nstarwars_tibble <- starwars %>% as_tibble()\n\nstarwars_tibble %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 87\nColumns: 14\n$ name       <chr> \"Luke Skywalker\", \"C-3PO\", \"R2-D2\", \"Darth Vader\", \"Leia Or…\n$ height     <int> 172, 167, 96, 202, 150, 178, 165, 97, 183, 182, 188, 180, 2…\n$ mass       <dbl> 77.0, 75.0, 32.0, 136.0, 49.0, 120.0, 75.0, 32.0, 84.0, 77.…\n$ hair_color <chr> \"blond\", NA, NA, \"none\", \"brown\", \"brown, grey\", \"brown\", N…\n$ skin_color <chr> \"fair\", \"gold\", \"white, blue\", \"white\", \"light\", \"light\", \"…\n$ eye_color  <chr> \"blue\", \"yellow\", \"red\", \"yellow\", \"brown\", \"blue\", \"blue\",…\n$ birth_year <dbl> 19.0, 112.0, 33.0, 41.9, 19.0, 52.0, 47.0, NA, 24.0, 57.0, …\n$ sex        <chr> \"male\", \"none\", \"none\", \"male\", \"female\", \"male\", \"female\",…\n$ gender     <chr> \"masculine\", \"masculine\", \"masculine\", \"masculine\", \"femini…\n$ homeworld  <chr> \"Tatooine\", \"Tatooine\", \"Naboo\", \"Tatooine\", \"Alderaan\", \"T…\n$ species    <chr> \"Human\", \"Droid\", \"Droid\", \"Human\", \"Human\", \"Human\", \"Huma…\n$ films      <list> <\"A New Hope\", \"The Empire Strikes Back\", \"Return of the J…\n$ vehicles   <list> <\"Snowspeeder\", \"Imperial Speeder Bike\">, <>, <>, <>, \"Imp…\n$ starships  <list> <\"X-wing\", \"Imperial shuttle\">, <>, <>, \"TIE Advanced x1\",…\n```\n\n\n:::\n\n```{.r .cell-code}\n# A quick dplyr reminder:\n# Find all droids taller than 100cm\nstarwars_tibble %>%\n  filter(species == \"Droid\" & height > 100) %>%\n  select(name, height, mass, homeworld) %>%\n  arrange(desc(height))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 4\n  name  height  mass homeworld\n  <chr>  <int> <dbl> <chr>    \n1 IG-88    200   140 <NA>     \n2 C-3PO    167    75 Tatooine \n```\n\n\n:::\n:::\n\n\n\n\n**Exercise 1.1: Quick Check**\n\nFamiliarize yourself again with a built-in dataset.\n1.  Load the `tidyverse` package.\n2.  Convert the `mtcars` dataset to a tibble.\n3.  Use `glimpse()` to see its structure.\n4.  Use `head()` to view the first few rows.\n5.  How many cars have more than 4 cylinders and achieve more than 20 miles per gallon (mpg)?\n\n\n\n\n::: {.cell exercise='ex1-1' solution_hidden='true'}\n```{webr}\n#| exercise: ex1-1\n#| solution_hidden: true\n# Inspect the built-in mtcars dataset: glimpse and head\nlibrary(tidyverse)\n\nmtcars_tbl <- as_tibble(mtcars, rownames = \"model\")\n\nglimpse(mtcars_tbl)\nhead(mtcars_tbl)\n\n# How many cars have more than 4 cylinders and achieve more than 20 miles per gallon (mpg)?\nmtcars_tbl %>%\n  filter(cyl > 4 & mpg > 20) %>%\n  nrow() # or count()\n```\n:::\n\n\n\n\n---\n\n## Lesson 2: Joins (Part I & II)\n\nOften, the data you need is spread across multiple tables. **Joins** are how we combine these tables based on common variables (keys).\n\n### Part I: Stacking Tables\n\nSometimes, you don't need to match rows based on keys, but rather stack tables on top of each other or side-by-side.\n\n*   **`bind_rows(...)`**: Stacks multiple data frames vertically.\n    *   It matches columns by name.\n    *   Columns that don't exist in one of the tables will be filled with `NA`.\n    *   You can use the `.id` argument to create a new column indicating the original data frame for each row.\n\n*   **`bind_cols(...)`**: Stacks multiple data frames horizontally.\n    *   This is less common for typical data analysis workflows because it requires the data frames to have the same number of rows and for those rows to correspond to each other (e.g., same observations in the same order).\n    *   If column names are duplicated, `bind_cols()` will automatically rename them.\n\n**Example: `bind_rows()`**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsales_q1 <- tribble(\n  ~product_id, ~units_sold, ~quarter,\n  \"A101\",      50,          \"Q1\",\n  \"B202\",      75,          \"Q1\"\n)\n\nsales_q2 <- tribble(\n  ~product_id, ~units_sold, ~revenue, ~quarter,\n  \"A101\",      60,          1200,     \"Q2\",\n  \"C303\",      90,          1800,     \"Q2\"\n)\n\nall_sales <- bind_rows(sales_q1, sales_q2, .id = \"source_table_id\")\nprint(all_sales)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  source_table_id product_id units_sold quarter revenue\n  <chr>           <chr>           <dbl> <chr>     <dbl>\n1 1               A101               50 Q1           NA\n2 1               B202               75 Q1           NA\n3 2               A101               60 Q2         1200\n4 2               C303               90 Q2         1800\n```\n\n\n:::\n:::\n\n\n\nNotice how `revenue` is `NA` for Q1 sales, and `source_table_id` tells us which original table the row came from.\n\n**Exercise 2.1: Stacking Sales Data**\n\nYou have three tibbles representing sales data for different regions. Combine them into a single tibble.\n\n\n\n\n::: {.cell exercise='ex2-1' solution_hidden='true'}\n```{webr}\n#| exercise: ex2-1\n#| solution_hidden: true\nlibrary(tidyverse)\n\nsales_north <- tribble(\n  ~month, ~product, ~sales,\n  \"Jan\",  \"Apple\",  100,\n  \"Feb\",  \"Banana\", 150\n)\n\nsales_south <- tribble(\n  ~month, ~product, ~sales, ~rep_id,\n  \"Jan\",  \"Apple\",  200,    \"S01\",\n  \"Mar\",  \"Orange\", 120,    \"S02\"\n)\n\nsales_west <- tribble(\n  ~month, ~product, ~sales, ~customer_segment,\n  \"Jan\",  \"Banana\", 50,     \"Retail\",\n  \"Feb\",  \"Apple\",  75,     \"Wholesale\"\n)\n\n# Your task: Use bind_rows() to stack these three tables.\n# What happens to columns not present in all tables?\n# Add an .id argument to track the source region.\n\ncombined_sales <- bind_rows(\n  North = sales_north,\n  South = sales_south,\n  West = sales_west,\n  .id = \"region\"\n)\n\nprint(combined_sales)\n```\n:::\n\n\n\n\n### Part II: Relational (dplyr) Joins\n\nThese joins combine data frames based on matching values in specified \"key\" columns.\n\n*   **Key Concepts**:\n    *   **Primary Key**: A column (or set of columns) in a table that uniquely identifies each row.\n    *   **Foreign Key**: A column (or set of columns) in one table that refers to the primary key in another table.\n    *   Joins work by matching foreign keys to primary keys.\n\n*   **Mutating Joins**: Add columns from one table to another.\n    *   `left_join(x, y, by = \"key_column\")`: Keeps all rows from `x` and all columns from `x` and `y`. Rows in `x` with no match in `y` will have `NA` values in the new columns from `y`.\n    *   `right_join(x, y, by = \"key_column\")`: Keeps all rows from `y`. Rows in `y` with no match in `x` will have `NA` values. (Less common, often you can achieve the same by swapping `x` and `y` in a `left_join`).\n    *   `inner_join(x, y, by = \"key_column\")`: Keeps only rows from `x` that have a match in `y`.\n    *   `full_join(x, y, by = \"key_column\")`: Keeps all rows from both `x` and `y`. If there are no matches, `NA`s are inserted.\n\n*   **Filtering Joins**: Filter rows from one table based on whether they match in another, but do *not* add columns.\n    *   `semi_join(x, y, by = \"key_column\")`: Keeps all rows from `x` that *have* a match in `y`. Does not duplicate rows in `x` if there are multiple matches in `y`.\n    *   `anti_join(x, y, by = \"key_column\")`: Keeps all rows from `x` that *do not* have a match in `y`. Useful for finding unmatched records.\n\n**Specifying Keys with `by`**:\n*   `by = \"key_col\"`: If the key column has the same name in both tables.\n*   `by = c(\"key_col_x\" = \"key_col_y\")`: If key columns have different names.\n*   `by = c(\"key1\", \"key2\")`: For multiple key columns (composite key), all with same names.\n*   `by = join_by(col_x == col_y, another_x == another_y)`: A more flexible `dplyr 1.1.0+` syntax for complex joins, including inequality or rolling joins (though we focus on equality here).\n\n**Example: `left_join` and `inner_join`**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npatients <- tribble(\n  ~patient_id, ~name,\n  1,           \"Alice\",\n  2,           \"Bob\",\n  3,           \"Charlie\"\n)\n\nvisits <- tribble(\n  ~visit_id, ~patient_id, ~visit_date,\n  101,       1,           \"2023-01-15\",\n  102,       2,           \"2023-01-20\",\n  103,       1,           \"2023-02-10\",\n  104,       4,           \"2023-02-15\" # Patient 4 not in patients table\n)\n\n# Left Join: Keep all patients, add visit info if available\npatients_left_visits <- left_join(patients, visits, by = \"patient_id\")\nprint(\"Left Join (patients to visits):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Left Join (patients to visits):\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(patients_left_visits) # Charlie will have NAs for visit_id, visit_date\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 4\n  patient_id name    visit_id visit_date\n       <dbl> <chr>      <dbl> <chr>     \n1          1 Alice        101 2023-01-15\n2          1 Alice        103 2023-02-10\n3          2 Bob          102 2023-01-20\n4          3 Charlie       NA <NA>      \n```\n\n\n:::\n\n```{.r .cell-code}\n# Inner Join: Keep only patients who had visits\npatients_inner_visits <- inner_join(patients, visits, by = \"patient_id\")\nprint(\"Inner Join (patients to visits):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Inner Join (patients to visits):\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(patients_inner_visits) # Charlie and Patient 4 from visits are excluded\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  patient_id name  visit_id visit_date\n       <dbl> <chr>    <dbl> <chr>     \n1          1 Alice      101 2023-01-15\n2          1 Alice      103 2023-02-10\n3          2 Bob        102 2023-01-20\n```\n\n\n:::\n\n```{.r .cell-code}\n# Anti Join: Which patients had no visits?\npatients_no_visits <- anti_join(patients, visits, by = \"patient_id\")\nprint(\"Anti Join (patients with no visits):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Anti Join (patients with no visits):\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(patients_no_visits) # Should show Charlie\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n  patient_id name   \n       <dbl> <chr>  \n1          3 Charlie\n```\n\n\n:::\n\n```{.r .cell-code}\n# Semi Join: Which patients had at least one visit? (returns columns of patients only)\npatients_with_visits_semi <- semi_join(patients, visits, by = \"patient_id\")\nprint(\"Semi Join (patients with visits):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Semi Join (patients with visits):\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(patients_with_visits_semi) # Should show Alice and Bob\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  patient_id name \n       <dbl> <chr>\n1          1 Alice\n2          2 Bob  \n```\n\n\n:::\n:::\n\n\n\n\n**Exercise 2.2: Joining Orders and Customers**\n\nYou have two tibbles: `customers` and `orders`.\n1.  Perform a `left_join()` to combine `orders` with `customers` data. Which orders don't have customer information?\n2.  Perform an `inner_join()` to see only orders with valid customer information.\n3.  Use `anti_join()` to find customers who have not placed any orders.\n\n\n\n\n::: {.cell exercise='ex2-2' solution_hidden='true'}\n```{webr}\n#| exercise: ex2-2\n#| solution_hidden: true\nlibrary(tidyverse)\n\ncustomers <- tribble(\n  ~customer_id, ~customer_name, ~city,\n  \"C1\",         \"John Smith\",   \"New York\",\n  \"C2\",         \"Jane Doe\",     \"London\",\n  \"C3\",         \"Mike Brown\",   \"Paris\",\n  \"C4\",         \"Lisa Ray\",     \"Tokyo\"\n)\n\norders <- tribble(\n  ~order_id, ~customer_id, ~order_date, ~amount,\n  \"O101\",    \"C1\",         \"2023-01-01\", 100,\n  \"O102\",    \"C2\",         \"2023-01-05\", 150,\n  \"O103\",    \"C5\",         \"2023-01-10\", 200, # Customer C5 doesn't exist\n  \"O104\",    \"C1\",         \"2023-01-15\", 50\n)\n\n# 1. Left join orders with customers\norders_with_customers_left <- left_join(orders, customers, by = \"customer_id\")\nprint(\"1. Orders Left Joined with Customers:\")\nprint(orders_with_customers_left)\n# Order O103 will have NAs for customer_name and city.\n\n# 2. Inner join orders with customers\norders_with_customers_inner <- inner_join(orders, customers, by = \"customer_id\")\nprint(\"2. Orders Inner Joined with Customers:\")\nprint(orders_with_customers_inner)\n# Order O103 will be excluded.\n\n# 3. Anti join to find customers with no orders\ncustomers_no_orders <- anti_join(customers, orders, by = \"customer_id\")\nprint(\"3. Customers with no orders:\")\nprint(customers_no_orders)\n# Mike Brown (C3) and Lisa Ray (C4) should appear.\n```\n:::\n\n\n\n\n---\n\n## Lesson 3: Pivoting & Reshaping Data\n\nData often comes in formats that are not ideal for analysis or plotting. **Pivoting** is the process of changing the shape of your data by turning:\n*   **Wide data into long data (`pivot_longer()`):** This is often needed when some column names are actually values of a variable.\n*   **Long data into wide data (`pivot_wider()`):** This is useful for creating summary tables or when variables are stored in rows.\n\nThe goal is often to achieve \"tidy data\" where:\n1.  Each variable forms a column.\n2.  Each observation forms a row.\n3.  Each type of observational unit forms a table.\n\n### `pivot_longer()`\n\nUse `pivot_longer()` when you have data spread across multiple columns, and those column names themselves represent values of a variable.\n\nKey arguments:\n*   `data`: The data frame to reshape.\n*   `cols`: The columns to pivot (gather). You can use dplyr select helpers like `starts_with()`, `ends_with()`, `everything()`, `c(col1, col2)`, etc.\n*   `names_to`: A string specifying the name of the new column that will store the *names* of the pivoted columns.\n*   `values_to`: A string specifying the name of the new column that will store the *values* from the pivoted columns.\n*   `names_prefix`: (Optional) A string prefix to remove from the column names before they become values in the `names_to` column.\n*   `names_sep` or `names_pattern`: (Optional) For more complex scenarios where column names encode multiple variables.\n*   `values_drop_na = TRUE`: (Optional) To drop rows where the value in the `values_to` column is `NA`.\n\n**Example: `pivot_longer()`**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwide_data <- tribble(\n  ~student_id, ~test1_score, ~test2_score, ~test3_score,\n  \"S101\",      85,           90,           88,\n  \"S102\",      78,           82,           80,\n  \"S103\",      92,           88,           95\n)\nprint(\"Wide Data:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wide Data:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(wide_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  student_id test1_score test2_score test3_score\n  <chr>            <dbl>       <dbl>       <dbl>\n1 S101                85          90          88\n2 S102                78          82          80\n3 S103                92          88          95\n```\n\n\n:::\n\n```{.r .cell-code}\nlong_data <- wide_data %>%\n  pivot_longer(\n    cols = starts_with(\"test\"), # or c(test1_score, test2_score, test3_score)\n    names_to = \"test_name\",\n    values_to = \"score\",\n    names_prefix = \"test\" # removes \"test\" from \"test1_score\" -> \"1_score\"\n    # A better approach for names_prefix or names_transform might be needed for cleaner test_name\n  )\n\n# For cleaner test names, we can use names_transform or further mutate\nlong_data_cleaner <- wide_data %>%\n  pivot_longer(\n    cols = -student_id, # pivot all columns except student_id\n    names_to = \"test_name_raw\",\n    values_to = \"score\"\n  ) %>%\n  mutate(test_number = str_extract(test_name_raw, \"\\\\d+\")) %>% # Extract number\n  select(student_id, test_number, score)\n\n\nprint(\"Long Data (Simpler):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Long Data (Simpler):\"\n```\n\n\n:::\n\n```{.r .cell-code}\nlong_data_simple_names <- wide_data %>%\n  pivot_longer(cols = c(test1_score, test2_score, test3_score),\n               names_to = \"test_id\",\n               values_to = \"score\")\nprint(long_data_simple_names)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 × 3\n  student_id test_id     score\n  <chr>      <chr>       <dbl>\n1 S101       test1_score    85\n2 S101       test2_score    90\n3 S101       test3_score    88\n4 S102       test1_score    78\n5 S102       test2_score    82\n6 S102       test3_score    80\n7 S103       test1_score    92\n8 S103       test2_score    88\n9 S103       test3_score    95\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(\"Long Data (using names_prefix):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Long Data (using names_prefix):\"\n```\n\n\n:::\n\n```{.r .cell-code}\nlong_data_prefix <- wide_data %>%\n  pivot_longer(\n    cols = starts_with(\"test\"),\n    names_to = \"test_number_suffix\",\n    values_to = \"score\",\n    names_prefix = \"test\" # results in \"1_score\", \"2_score\" etc.\n  )\nprint(long_data_prefix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 9 × 3\n  student_id test_number_suffix score\n  <chr>      <chr>              <dbl>\n1 S101       1_score               85\n2 S101       2_score               90\n3 S101       3_score               88\n4 S102       1_score               78\n5 S102       2_score               82\n6 S102       3_score               80\n7 S103       1_score               92\n8 S103       2_score               88\n9 S103       3_score               95\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(\"Long Data (using names_pattern for more complex extraction):\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Long Data (using names_pattern for more complex extraction):\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# If columns were like test_1_score, test_2_score\n# wide_data_complex_names <- tribble(\n#   ~student_id, ~test_1_score, ~test_2_score,\n#   \"S101\",      85,           90,\n# )\n# long_data_pattern <- wide_data_complex_names %>%\n#   pivot_longer(\n#     cols = starts_with(\"test\"),\n#     names_to = c(\".value\", \"test_number\"), # .value takes part before _\n#     names_pattern = \"test_([0-9]+)_(.*)\", # Captures number and \"score\"\n#     # This is more advanced; for now, focus on simpler names_to/values_to\n#   )\n# print(long_data_pattern)\n```\n:::\n\n\n\n\n**Exercise 3.1: Long Format for Lab Results**\n\nYou have a tibble `lab_results_wide` where each row is a patient, and columns represent different lab tests taken on different days (e.g., `glucose_day1`, `hgb_day1`, `glucose_day7`, `hgb_day7`). Convert this to a long format with columns: `patient_id`, `test_type`, `day`, `value`.\n\n\n\n\n::: {.cell exercise='ex3-1' solution_hidden='true'}\n```{webr}\n#| exercise: ex3-1\n#| solution_hidden: true\nlibrary(tidyverse)\n\nlab_results_wide <- tribble(\n  ~patient_id, ~glucose_day1, ~hgb_day1, ~glucose_day7, ~hgb_day7,\n  \"P001\",      105,           14.1,      110,           13.9,\n  \"P002\",      99,            13.5,      102,           13.6,\n  \"P003\",      120,           15.0,      115,           14.8\n)\nprint(\"Original Wide Data:\")\nprint(lab_results_wide)\n\n# Your task: Convert lab_results_wide to a long format.\n# Hint: You might need pivot_longer() and then separate() or extract()\n# on the new 'name' column.\n\nlab_results_long <- lab_results_wide %>%\n  pivot_longer(\n    cols = -patient_id, # Select all columns except patient_id\n    names_to = \"test_day_raw\",\n    values_to = \"value\"\n  ) %>%\n  separate(\n    col = test_day_raw,\n    into = c(\"test_type\", \"day_raw\"),\n    sep = \"_day\" # Split at \"_day\"\n  ) %>%\n  mutate(day = as.integer(day_raw)) %>% # Convert day to integer\n  select(patient_id, test_type, day, value)\n\nprint(\"Long Format Lab Results:\")\nprint(lab_results_long)\n```\n:::\n\n\n\n\n### `pivot_wider()`\n\nUse `pivot_wider()` when you have observations scattered across multiple rows, and you want to consolidate them into a wider format. This is the inverse of `pivot_longer()`.\n\nKey arguments:\n*   `data`: The data frame to reshape.\n*   `names_from`: The column whose *values* will become new column *names*.\n*   `values_from`: The column whose *values* will fill the new columns.\n*   `values_fill`: (Optional) A value to use if a combination of `id_cols` and `names_from` doesn't exist (to fill explicit NAs).\n*   `id_cols`: (Optional) Columns that uniquely identify each observation unit, which will be kept as is. If not specified, all columns not used in `names_from` or `values_from` are used.\n\n**Example: `pivot_wider()`**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlong_sensor_data <- tribble(\n  ~timestamp,          ~sensor_id, ~metric, ~value,\n  \"2023-03-15 10:00:00\", \"SensorA\",  \"temp\",  25.5,\n  \"2023-03-15 10:00:00\", \"SensorA\",  \"humid\", 60.1,\n  \"2023-03-15 10:00:00\", \"SensorB\",  \"temp\",  26.1,\n  \"2023-03-15 10:00:00\", \"SensorB\",  \"humid\", 58.5,\n  \"2023-03-15 10:01:00\", \"SensorA\",  \"temp\",  25.6,\n  \"2023-03-15 10:01:00\", \"SensorA\",  \"humid\", 60.3\n)\nprint(\"Long Sensor Data:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Long Sensor Data:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(long_sensor_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 4\n  timestamp           sensor_id metric value\n  <chr>               <chr>     <chr>  <dbl>\n1 2023-03-15 10:00:00 SensorA   temp    25.5\n2 2023-03-15 10:00:00 SensorA   humid   60.1\n3 2023-03-15 10:00:00 SensorB   temp    26.1\n4 2023-03-15 10:00:00 SensorB   humid   58.5\n5 2023-03-15 10:01:00 SensorA   temp    25.6\n6 2023-03-15 10:01:00 SensorA   humid   60.3\n```\n\n\n:::\n\n```{.r .cell-code}\nwide_sensor_data <- long_sensor_data %>%\n  pivot_wider(\n    id_cols = c(timestamp, sensor_id), # Columns to keep as identifiers for rows\n    names_from = metric,\n    values_from = value\n  )\nprint(\"Wide Sensor Data:\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Wide Sensor Data:\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(wide_sensor_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 4\n  timestamp           sensor_id  temp humid\n  <chr>               <chr>     <dbl> <dbl>\n1 2023-03-15 10:00:00 SensorA    25.5  60.1\n2 2023-03-15 10:00:00 SensorB    26.1  58.5\n3 2023-03-15 10:01:00 SensorA    25.6  60.3\n```\n\n\n:::\n:::\n\n\n\n\n**Exercise 3.2: Reconstruct Summary Table**\n\nYou have `long_summary_data` with columns `country`, `year`, `metric_name`, `value`. Convert this to a wide format where each `metric_name` becomes a column.\n\n\n\n\n::: {.cell exercise='ex3-2' solution_hidden='true'}\n```{webr}\n#| exercise: ex3-2\n#| solution_hidden: true\nlibrary(tidyverse)\n\nlong_summary_data <- tribble(\n  ~country, ~year, ~metric_name, ~value,\n  \"USA\",    2020,  \"GDP\",        20.94,\n  \"USA\",    2020,  \"Population\", 331,\n  \"China\",  2020,  \"GDP\",        14.72,\n  \"China\",  2020,  \"Population\", 1444,\n  \"USA\",    2021,  \"GDP\",        22.99,\n  \"USA\",    2021,  \"Population\", 332\n)\nprint(\"Original Long Summary Data:\")\nprint(long_summary_data)\n\n# Your task: Use pivot_wider() to make GDP and Population their own columns.\nwide_summary_data <- long_summary_data %>%\n  pivot_wider(\n    id_cols = c(country, year),\n    names_from = metric_name,\n    values_from = value\n  )\n\nprint(\"Wide Summary Data:\")\nprint(wide_summary_data)\n```\n:::\n\n\n\n\n---\n\n## Lesson 4: String Operations with {stringr}\n\nText data is ubiquitous. The **{stringr}** package provides a cohesive set of functions for common string manipulations, often wrapping base R string functions or those from the `stringi` package in a more consistent and pipe-friendly way. Most `stringr` functions start with `str_`.\n\n### Detecting and Subsetting Patterns\n\n*   `str_detect(string, pattern)`: Detects the presence of a `pattern` in a `string`. Returns a logical vector.\n    *   `pattern` can be a literal string or a regular expression.\n*   `str_subset(string, pattern)`: Returns only the elements of `string` that match the `pattern`.\n*   `str_count(string, pattern)`: Counts the number of matches of `pattern` in each string.\n\n**Example:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfruit <- c(\"apple\", \"banana\", \"pear\", \"pineapple\")\n\nstr_detect(fruit, \"a\")        # TRUE TRUE TRUE TRUE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE TRUE TRUE TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(fruit, \"^a\")       # TRUE FALSE FALSE FALSE (starts with 'a')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE FALSE FALSE FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(fruit, \"a$\")       # FALSE TRUE FALSE FALSE (ends with 'a')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE  TRUE FALSE FALSE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_detect(fruit, \"[aeiou]\") # TRUE TRUE TRUE TRUE (contains any vowel)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE TRUE TRUE TRUE\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_subset(fruit, \"apple\")    # \"apple\" \"pineapple\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"apple\"     \"pineapple\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_subset(fruit, \"^p\")       # \"pear\" \"pineapple\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"pear\"      \"pineapple\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_count(fruit, \"p\")         # 2 0 1 2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2 0 1 3\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_count(fruit, \"[aeiou]\")   # 2 3 2 4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2 3 2 4\n```\n\n\n:::\n:::\n\n\n\n\n### Replacing Patterns\n\n*   `str_replace(string, pattern, replacement)`: Replaces the *first* occurrence of `pattern` with `replacement`.\n*   `str_replace_all(string, pattern, replacement)`: Replaces *all* occurrences of `pattern`.\n    *   You can use a named vector for `pattern` and `replacement` to perform multiple replacements simultaneously.\n*   `str_remove(string, pattern)`: Shortcut for `str_replace(string, pattern, \"\")`.\n*   `str_remove_all(string, pattern)`: Shortcut for `str_replace_all(string, pattern, \"\")`.\n\n**Example:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntext_data <- c(\"Color: Red\", \"Colour: Blue\", \"Color: Green\")\n\nstr_replace(text_data, \"Color\", \"Colour\") # Only first match in each string\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Colour: Red\"   \"Colour: Blue\"  \"Colour: Green\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_replace_all(text_data, \"Colou?r\", \"Hue\") # Using regex ? for optional 'u'\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hue: Red\"   \"Hue: Blue\"  \"Hue: Green\"\n```\n\n\n:::\n\n```{.r .cell-code}\nids <- c(\"ID_123\", \"ID_456\", \"REF_789\")\nstr_remove_all(ids, \"ID_|_\") # \"123\" \"456\" \"REF789\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"123\"    \"456\"    \"REF789\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_remove_all(ids, \"ID_?|REF_?\") # \"123\" \"456\" \"789\" (more precise)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"123\" \"456\" \"789\"\n```\n\n\n:::\n:::\n\n\n\n\n### Splitting Strings\n\n*   `str_split(string, pattern, n = Inf, simplify = FALSE)`: Splits strings into pieces based on `pattern`.\n    *   Returns a list by default.\n    *   If `simplify = TRUE`, returns a character matrix (useful if `pattern` yields same number of pieces for each string).\n*   `str_split_fixed(string, pattern, n)`: A variation that always returns a character matrix, splitting into exactly `n` pieces. If fewer pieces are found, fills with `\"\"`. If more, the `n`-th piece contains the rest of the string.\n\n**Example:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfilenames <- c(\"report_2023_final.docx\", \"data_2022_raw.csv\", \"image.png\")\n\nstr_split(filenames, pattern = \"_\") # Returns a list\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[[1]]\n[1] \"report\"     \"2023\"       \"final.docx\"\n\n[[2]]\n[1] \"data\"    \"2022\"    \"raw.csv\"\n\n[[3]]\n[1] \"image.png\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_split(filenames, pattern = \"_\", n = 2, simplify = TRUE) # Matrix, splits at first \"_\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]        [,2]             \n[1,] \"report\"    \"2023_final.docx\"\n[2,] \"data\"      \"2022_raw.csv\"   \n[3,] \"image.png\" \"\"               \n```\n\n\n:::\n\n```{.r .cell-code}\nstr_split_fixed(filenames, pattern = \"\\\\.\", n = 2) # Split at literal \".\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]                [,2]  \n[1,] \"report_2023_final\" \"docx\"\n[2,] \"data_2022_raw\"     \"csv\" \n[3,] \"image\"             \"png\" \n```\n\n\n:::\n:::\n\n\n\n\n### Whitespace and Case\n\n*   `str_trim(string, side = \"both\")`: Removes leading and/or trailing whitespace. `side` can be \"left\", \"right\", or \"both\".\n*   `str_squish(string)`: Removes all excess whitespace: leading/trailing, and reduces internal consecutive whitespace to a single space.\n*   `str_to_lower(string)`, `str_to_upper(string)`, `str_to_title(string)`: Convert case.\n\n**Example:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmessy_text <- \"  Hello   World!  \"\nstr_trim(messy_text)    # \"Hello   World!\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello   World!\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_squish(messy_text)  # \"Hello World!\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hello World!\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstr_to_upper(\"Hello World\") # \"HELLO WORLD\"\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"HELLO WORLD\"\n```\n\n\n:::\n:::\n\n\n\n\n### A Brief Note on Regular Expressions (Regex)\n\nMany `stringr` functions accept **regular expressions** for `pattern`. Regex is a powerful mini-language for describing text patterns.\n*   `.`: Matches any single character (except newline).\n*   `^`: Matches the start of the string.\n*   `$`: Matches the end of the string.\n*   `*`: Matches the preceding item 0 or more times.\n*   `+`: Matches the preceding item 1 or more times.\n*   `?`: Matches the preceding item 0 or 1 time (optional).\n*   `\\\\d`: Matches a digit. `\\\\D` matches non-digit.\n*   `\\\\s`: Matches whitespace. `\\\\S` matches non-whitespace.\n*   `[abc]`: Matches 'a', 'b', or 'c'.\n*   `[^abc]`: Matches any character *except* 'a', 'b', or 'c'.\n*   `(pattern)`: Groups a pattern. Useful for `str_extract` or backreferences.\n*   `\\\\`: Escape special characters (e.g., `\\\\.` to match a literal dot).\n\nLearning regex takes time but is incredibly useful for complex text processing.\n\n**Exercise 4.1: Clean Up Product Descriptions**\n\nYou have a tibble with a `product_desc` column containing messy descriptions.\n1.  Convert all descriptions to lowercase.\n2.  Remove any leading/trailing whitespace.\n3.  Replace multiple internal spaces with a single space.\n4.  Remove all punctuation (e.g., `!`, `.`, `,`).\n\n\n\n\n::: {.cell exercise='ex4-1' solution_hidden='true'}\n```{webr}\n#| exercise: ex4-1\n#| solution_hidden: true\nlibrary(tidyverse)\n\nproducts <- tribble(\n  ~product_id, ~product_desc,\n  1,           \"  RED T-Shirt, size L!  \",\n  2,           \"Blue Jeans - Slim FIT.\",\n  3,           \"  Green  Socks (3-pack)  \"\n)\nprint(\"Original Product Data:\")\nprint(products)\n\n# Your task: Clean product_desc\ncleaned_products <- products %>%\n  mutate(\n    product_desc_clean = str_to_lower(product_desc),\n    product_desc_clean = str_squish(product_desc_clean), # Handles leading/trailing and internal spaces\n    product_desc_clean = str_remove_all(product_desc_clean, \"[[:punct:]]\") # Removes all punctuation\n    # Alternative for punctuation: str_replace_all(product_desc_clean, \"[^[:alnum:][:space:]]\", \"\")\n    # This keeps alphanumeric and spaces, removes everything else.\n  )\n\nprint(\"Cleaned Product Data:\")\nprint(cleaned_products)\n```\n:::\n\n\n\n\n**Exercise 4.2: Extract Information from Log Entries**\n\nYou have log entries like `\"INFO:2023-03-15:User_JohnDoe:Logged_In\"`.\nExtract the `date`, `user_id`, and `action` into separate columns.\n\n\n\n\n::: {.cell exercise='ex4-2' solution_hidden='true'}\n```{webr}\n#| exercise: ex4-2\n#| solution_hidden: true\nlibrary(tidyverse)\n\nlog_entries <- tibble(\n  entry = c(\n    \"INFO:2023-03-15:User_JohnDoe:Logged_In\",\n    \"WARN:2023-03-16:User_JaneRoe:Failed_Login_Attempt\",\n    \"INFO:2023-03-17:User_Admin:System_Shutdown\"\n  )\n)\nprint(\"Original Log Entries:\")\nprint(log_entries)\n\n# Your task: Extract date, user_id, and action\n# Hint: str_split_fixed or str_extract_all with regex might be useful.\n# Using str_split_fixed is simpler here if the structure is consistent.\n\nextracted_logs <- log_entries %>%\n  separate(\n    col = entry,\n    into = c(\"log_level\", \"date\", \"user_raw\", \"action\"),\n    sep = \":\", # Split by colon\n    extra = \"merge\" # If action has colons, merge them\n  ) %>%\n  mutate(\n    user_id = str_remove(user_raw, \"^User_\") # Remove \"User_\" prefix\n  ) %>%\n  select(log_level, date, user_id, action)\n\nprint(\"Extracted Log Information:\")\nprint(extracted_logs)\n\n# Alternative using str_match (regex based extraction)\n# This is more robust if the number of colons can vary before the main parts.\nextracted_logs_regex <- log_entries %>%\n  mutate(\n    matches = str_match(entry, \"^([^:]+):([^:]+):User_([^:]+):(.*)$\")\n  ) %>%\n  mutate(\n    log_level = matches[,2],\n    date = matches[,3],\n    user_id = matches[,4],\n    action = matches[,5]\n  ) %>%\n  select(log_level, date, user_id, action)\n\nprint(\"Extracted Log Information (Regex):\")\nprint(extracted_logs_regex)\n\n```\n:::\n\n\n\n\n---\n\n## Lesson 5: Date-Time Operations with {lubridate}\n\nWorking with dates and times can be notoriously tricky. The **{lubridate}** package, part of the Tidyverse, makes it significantly easier by providing intuitive functions to parse, manipulate, and compute with date-time objects.\n\nKey features of {lubridate}:\n*   **Easy Parsing**: Functions like `ymd()`, `mdy()`, `dmy()`, `ymd_hms()` can automatically parse dates and times from strings in various formats.\n*   **Accessing Components**: Functions like `year()`, `month()`, `day()`, `hour()`, `minute()`, `second()`, `wday()` (day of the week), `yday()` (day of the year) allow easy extraction of specific components.\n*   **Time Spans**: {lubridate} defines three types of time spans:\n    *   **Durations**: Exact number of seconds (e.g., `dseconds()`, `dminutes()`, `ddays()`).\n    *   **Periods**: Human-readable units that account for irregularities like leap years and daylight saving (e.g., `seconds()`, `minutes()`, `days()`, `months()`, `years()`).\n    *   **Intervals**: A time span between two specific date-times.\n*   **Arithmetic**: Perform arithmetic directly on date-times (e.g., adding days, finding differences).\n\n**Example: Parsing and Components**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lubridate)\n\ndate_string1 <- \"2024-07-15\"\ndate_string2 <- \"July 15, 2024 14:30:00\"\ndate_string3 <- \"15/07/2024\"\n\ndt1 <- ymd(date_string1)\ndt2 <- mdy_hms(date_string2)\ndt3 <- dmy(date_string3)\n\nprint(dt1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-07-15\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(dt2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-07-15 14:30:00 UTC\"\n```\n\n\n:::\n\n```{.r .cell-code}\nprint(dt3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-07-15\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste(\"Year:\", year(dt1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Year: 2024\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste(\"Month:\", month(dt1, label = TRUE, abbr = FALSE)) # Full month name\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Month: July\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste(\"Day of week:\", wday(dt1, label = TRUE, abbr = FALSE)) # Full day name\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Day of week: Monday\"\n```\n\n\n:::\n\n```{.r .cell-code}\npaste(\"Hour of dt2:\", hour(dt2))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Hour of dt2: 14\"\n```\n\n\n:::\n:::\n\n\n\n\n**Example: Time Spans and Arithmetic**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstart_date <- ymd(\"2024-01-01\")\nend_date <- ymd(\"2025-03-15\")\n\n# Add 10 days to start_date\nstart_date + ddays(10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-01-11\"\n```\n\n\n:::\n\n```{.r .cell-code}\nstart_date + days(10) # Period, often same for days\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-01-11\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Add 2 months\nstart_date + months(2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"2024-03-01\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Difference between dates\ntime_difference_days <- end_date - start_date # Returns a difftime object\nprint(time_difference_days)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime difference of 439 days\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a duration\none_week_duration <- dweeks(1)\nprint(one_week_duration)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"604800s (~1 weeks)\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Create a period\none_month_period <- months(1)\nprint(one_month_period)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"1m 0d 0H 0M 0S\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Interval\nevent_interval <- interval(start_date, end_date)\nprint(event_interval)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2024-01-01 UTC--2025-03-15 UTC\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check if a date is within an interval\nymd(\"2024-06-01\") %within% event_interval # TRUE\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\n**Exercise 5.1: Analyzing Event Durations**\n\nYou have a tibble of project tasks with start and end dates.\n1.  Parse the `start_date` and `end_date` strings into date objects.\n2.  Calculate the duration of each task in days.\n3.  Extract the year and month the task started.\n4.  Determine which day of the week each task ended.\n5.  Filter for tasks that lasted longer than 30 days.\n\n\n\n\n::: {.cell exercise='ex5-1' solution_hidden='true'}\n```{webr}\n#| exercise: ex5-1\n#| solution_hidden: true\nlibrary(tidyverse)\nlibrary(lubridate)\n\ntasks <- tribble(\n  ~task_id, ~task_name,         ~start_date_str, ~end_date_str,\n  \"T101\",   \"Initial Planning\", \"2023-01-15\",    \"2023-02-10\",\n  \"T102\",   \"Development Phase1\", \"2023-02-11\",    \"2023-04-05\",\n  \"T103\",   \"Testing\",            \"2023-04-06\",    \"2023-04-20\",\n  \"T104\",   \"Deployment\",         \"2023-04-21\",    \"2023-04-25\"\n)\nprint(\"Original Task Data:\")\nprint(tasks)\n\ntasks_analyzed <- tasks %>%\n  mutate(\n    # 1. Parse dates\n    start_date = ymd(start_date_str),\n    end_date = ymd(end_date_str),\n\n    # 2. Calculate duration in days\n    # duration_interval = interval(start_date, end_date),\n    # duration_days = as.duration(duration_interval) / ddays(1)\n    # Simpler for just days:\n    duration_days = as.numeric(end_date - start_date, units = \"days\"),\n\n    # 3. Extract year and month of start\n    start_year = year(start_date),\n    start_month = month(start_date, label = TRUE, abbr = FALSE),\n\n    # 4. Day of week task ended\n    end_day_of_week = wday(end_date, label = TRUE, abbr = FALSE)\n  )\n\nprint(\"Analyzed Task Data:\")\nprint(tasks_analyzed %>% select(-start_date_str, -end_date_str))\n\n# 5. Filter for tasks longer than 30 days\nlong_tasks <- tasks_analyzed %>%\n  filter(duration_days > 30)\n\nprint(\"Tasks longer than 30 days:\")\nprint(long_tasks %>% select(task_name, duration_days))\n```\n:::\n\n\n\n\n**Exercise 5.2: Scheduling Appointments**\n\nYou have a list of appointment requests with a preferred date and time.\n1.  Parse `preferred_datetime_str` into a datetime object. Assume UTC for simplicity if no timezone is given, or parse with a specific timezone.\n2.  If an appointment is requested before 9 AM or after 5 PM (17:00), flag it as \"AfterHours\".\n3.  Calculate the time until each appointment from a reference datetime (e.g., `now()`, or a fixed datetime for reproducibility).\n4.  Round appointment times to the nearest half hour.\n\n\n\n\n::: {.cell exercise='ex5-2' solution_hidden='true'}\n```{webr}\n#| exercise: ex5-2\n#| solution_hidden: true\nlibrary(tidyverse)\nlibrary(lubridate)\n\nappointment_requests <- tribble(\n  ~request_id, ~client_name, ~preferred_datetime_str,\n  \"R001\",      \"Alice\",      \"2024-08-01 10:00:00\",\n  \"R002\",      \"Bob\",        \"2024-08-01 08:30:00\", # Early\n  \"R003\",      \"Charlie\",    \"2024-08-02 17:45:00\", # Late\n  \"R004\",      \"Diana\",      \"2024-08-03 14:12:00\"\n)\nprint(\"Original Appointment Requests:\")\nprint(appointment_requests)\n\n# For reproducibility, let's use a fixed \"current\" time\ncurrent_time_fixed <- ymd_hms(\"2024-07-20 12:00:00\", tz = \"UTC\")\n\nappointments_scheduled <- appointment_requests %>%\n  mutate(\n    # 1. Parse datetime (assume UTC if not specified)\n    preferred_datetime = ymd_hms(preferred_datetime_str, tz = \"UTC\"),\n\n    # 2. Flag AfterHours\n    appointment_hour = hour(preferred_datetime),\n    is_after_hours = if_else(appointment_hour < 9 | appointment_hour >= 17, TRUE, FALSE),\n\n    # 3. Time until appointment\n    time_until = preferred_datetime - current_time_fixed, # difftime object\n\n    # 4. Round to nearest half hour\n    rounded_datetime = round_date(preferred_datetime, unit = \"30minutes\")\n  )\n\nprint(\"Scheduled Appointments Analysis:\")\nprint(appointments_scheduled %>% select(-preferred_datetime_str))\n```\n:::\n\n\n\n\n---\n\n## Lesson 6: Graphics I ({ggplot2} Essentials)\n\nThe **{ggplot2}** package, created by Hadley Wickham, is a powerful and versatile system for creating static graphics in R. It's based on the \"Grammar of Graphics,\" which allows you to build plots layer by layer.\n\nCore components of a ggplot:\n1.  **Data**: The dataset being plotted (must be a data frame or tibble).\n2.  **Aesthetic Mappings (`aes()`)**: How variables in your data map to visual properties (aesthetics) of the plot. Examples: `x`, `y`, `color`, `shape`, `size`, `fill`, `alpha`.\n3.  **Geoms (`geom_...()`)**: Geometric objects that represent your data. Examples: `geom_point()`, `geom_line()`, `geom_bar()`, `geom_histogram()`, `geom_boxplot()`, `geom_sf()`.\n4.  **Scales (`scale_...()`)**: Control how data values are mapped to aesthetic values (e.g., color gradients, axis limits, breaks, labels).\n5.  **Facets (`facet_...()`)**: Create small multiples (subplots) based on levels of a categorical variable (e.g., `facet_wrap()`, `facet_grid()`).\n6.  **Coordinates (`coord_...()`)**: Control the coordinate system (e.g., `coord_flip()` to swap x/y, `coord_polar()`).\n7.  **Themes (`theme_...()`)**: Control the overall appearance of the plot (non-data elements like background, gridlines, fonts).\n\n**Basic Plot Structure:**\n```r\n# ggplot(data = <DATA>) +\n#   <GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))\n```\n\n**Example: Scatter Plot**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ndata(mpg) # Using the built-in mpg dataset\n\n# Scatter plot of engine displacement (displ) vs. highway mpg (hwy)\n# Colored by car class\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = class)) +\n  geom_point() +\n  labs(\n    title = \"Engine Displacement vs. Highway MPG\",\n    x = \"Engine Displacement (Liters)\",\n    y = \"Highway Miles Per Gallon\",\n    color = \"Car Class\",\n    caption = \"Source: mpg dataset\"\n  ) +\n  theme_minimal() # Apply a minimal theme\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/lesson6-ggplot-scatter-1.png){width=672}\n:::\n:::\n\n\n\n\n**Example: Bar Plot**\nBar plots can represent counts or pre-summarized values.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Bar plot of car counts by manufacturer\nggplot(data = mpg, mapping = aes(x = manufacturer)) +\n  geom_bar(fill = \"steelblue\", color = \"black\") + # Counts are calculated by geom_bar\n  labs(title = \"Number of Car Models by Manufacturer\", x = \"Manufacturer\", y = \"Count\") +\n  theme_light() +\n  coord_flip() # Flip coordinates to make manufacturer names readable\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/lesson6-ggplot-bar-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# If data is already summarized:\nmanufacturer_summary <- mpg %>% count(manufacturer, name = \"count\")\nggplot(data = manufacturer_summary, mapping = aes(x = manufacturer, y = count)) +\n  geom_col(fill = \"darkgreen\", color = \"black\") + # Use geom_col for pre-summarized data\n  labs(title = \"Number of Car Models by Manufacturer (Pre-summarized)\", x = \"Manufacturer\", y = \"Count\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) # Rotate x-axis labels\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/lesson6-ggplot-bar-2.png){width=672}\n:::\n:::\n\n\n\n\n**Exercise 6.1: Exploring Fuel Efficiency**\n\nUsing the `mpg` dataset:\n1.  Create a scatter plot showing city miles per gallon (`cty`) vs. highway miles per gallon (`hwy`).\n2.  Color the points by `drv` (drive train: f=front, r=rear, 4=4wd).\n3.  Add a title and appropriate axis labels.\n4.  Experiment with `geom_smooth(method = \"lm\")` to add a linear regression line for each `drv` group.\n\n\n\n\n::: {.cell exercise='ex6-1' solution_hidden='true'}\n```{webr}\n#| exercise: ex6-1\n#| solution_hidden: true\nlibrary(tidyverse)\nlibrary(ggplot2)\n# data(mpg) # already loaded if tidyverse is loaded\n\n# 1, 2, 3. Scatter plot cty vs hwy, colored by drv\nggplot(data = mpg, mapping = aes(x = cty, y = hwy, color = drv)) +\n  geom_point(alpha = 0.7) + # Added alpha for better visibility of overlapping points\n  labs(\n    title = \"City MPG vs. Highway MPG by Drive Train\",\n    x = \"City Miles Per Gallon (MPG)\",\n    y = \"Highway Miles Per Gallon (MPG)\",\n    color = \"Drive Train\"\n  ) +\n  theme_minimal() +\n  # 4. Add linear regression lines\n  geom_smooth(method = \"lm\", se = FALSE) # se = FALSE removes confidence interval ribbon\n```\n:::\n\n\n\n\n**Exercise 6.2: Distribution of Highway MPG**\n\n1.  Create a histogram of highway miles per gallon (`hwy`).\n2.  Use `facet_wrap(~ class)` to create separate histograms for each car `class`.\n3.  Customize the bin width or number of bins for the histogram.\n4.  Add a vertical line representing the mean `hwy` for each class.\n\n\n\n\n::: {.cell exercise='ex6-2' solution_hidden='true'}\n```{webr}\n#| exercise: ex6-2\n#| solution_hidden: true\nlibrary(tidyverse)\nlibrary(ggplot2)\n# data(mpg)\n\n# 1, 2, 3. Histogram of hwy, faceted by class\nggplot(data = mpg, mapping = aes(x = hwy)) +\n  geom_histogram(binwidth = 2, fill = \"skyblue\", color = \"black\", alpha = 0.8) +\n  facet_wrap(~ class, scales = \"free_y\") + # scales = \"free_y\" allows y-axis to vary\n  labs(\n    title = \"Distribution of Highway MPG by Car Class\",\n    x = \"Highway Miles Per Gallon (MPG)\",\n    y = \"Frequency (Count)\"\n  ) +\n  theme_light() +\n  # 4. Add mean hwy line for each class\n  geom_vline(\n    data = mpg %>% group_by(class) %>% summarize(mean_hwy = mean(hwy, na.rm = TRUE)),\n    mapping = aes(xintercept = mean_hwy),\n    color = \"red\",\n    linetype = \"dashed\",\n    linewidth = 1\n  )\n```\n:::\n\n\n\n\n---\n\n## Lesson 7: Graphics II (Advanced {ggplot2})\n\nBuilding on the essentials, we can further customize and enhance our {ggplot2} visualizations.\n\n### Scales\nScales control the mapping from data values to aesthetics. You can customize axes, colors, sizes, etc.\n*   **Position Scales (x and y axes)**: `scale_x_continuous()`, `scale_y_continuous()`, `scale_x_discrete()`, `scale_y_discrete()`, `scale_x_log10()`, `scale_x_date()`.\n    *   Control `limits`, `breaks`, `labels`.\n*   **Color and Fill Scales**: `scale_color_brewer()`, `scale_fill_brewer()` (for discrete variables using ColorBrewer palettes), `scale_color_gradient()`, `scale_fill_gradient()` (for continuous variables), `scale_color_manual()`, `scale_fill_manual()` (for specifying colors manually).\n*   **Shape and Size Scales**: `scale_shape_manual()`, `scale_size_continuous()`.\n\n**Example: Customizing Scales**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = mpg, mapping = aes(x = displ, y = hwy, color = cty)) +\n  geom_point(size = 3) +\n  scale_x_continuous(\n    name = \"Engine Displacement (Liters)\",\n    breaks = seq(1, 7, by = 1),\n    limits = c(1, 7)\n  ) +\n  scale_y_continuous(\n    name = \"Highway MPG\",\n    labels = scales::label_comma() # Use comma for thousands, etc.\n  ) +\n  scale_color_gradient(low = \"blue\", high = \"red\", name = \"City MPG\") +\n  labs(title = \"Customized Scales Example\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/lesson7-ggplot-scales-1.png){width=672}\n:::\n:::\n\n\n\n\n### Themes\nThemes control the non-data elements of the plot.\n*   **Built-in Themes**: `theme_gray()` (default), `theme_bw()`, `theme_minimal()`, `theme_classic()`, `theme_light()`, `theme_dark()`, `theme_void()`.\n*   **Customizing Theme Elements**: Use `theme()` to modify specific elements like `plot.title`, `axis.text`, `axis.title`, `legend.position`, `panel.background`, `panel.grid`.\n\n**Example: Custom Theme**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = mpg, mapping = aes(x = class, fill = drv)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Car Count by Class and Drive Train\", x = \"Class\", y = \"Count\", fill = \"Drive Train\") +\n  theme_classic() + # Start with a classic theme\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 10),\n    axis.title = element_text(size = 12),\n    legend.position = \"top\", # \"bottom\", \"left\", \"right\", \"none\", or c(x,y) coordinates\n    panel.grid.major.y = element_line(color = \"grey80\", linetype = \"dashed\"),\n    panel.background = element_rect(fill = \"aliceblue\")\n  )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/lesson7-ggplot-theme-1.png){width=672}\n:::\n:::\n\n\n\n\n### Annotations and Saving Plots\n*   **Annotations**: Add text (`geom_text()`, `annotate(\"text\", ...)`), lines (`geom_hline()`, `geom_vline()`), rectangles (`annotate(\"rect\", ...)`).\n*   **Saving Plots**: Use `ggsave()` to save plots to files (e.g., PNG, PDF, SVG). It infers the type from the extension.\n\n**Example: Annotations and Saving**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This plot won't render in the QMD output directly if ggsave is used without printing the plot\n# For demonstration, we'll build it and then mention ggsave.\n\np <- ggplot(data = filter(mpg, manufacturer == \"audi\"), aes(x = year, y = hwy)) +\n  geom_jitter(width = 0.1, height = 0, alpha = 0.7, color = \"darkblue\") +\n  geom_smooth(method = \"loess\", color = \"red\", se = FALSE) +\n  annotate(\n    \"text\", x = 2004, y = 30,\n    label = \"Trend for Audi Highway MPG\",\n    color = \"darkred\", fontface = \"italic\"\n  ) +\n  labs(title = \"Audi Highway MPG Over Years\", x = \"Year\", y = \"Highway MPG\") +\n  theme_bw()\n\nprint(p) # Display the plot\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 1999\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 9.045\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 0\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 81.812\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/lesson7-ggplot-annotations-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# To save:\n# ggsave(\"audi_mpg_plot.png\", plot = p, width = 8, height = 6, dpi = 300)\n```\n:::\n\n\n\n\n**Exercise 7.1: Polished Boxplot of MPG**\n\nUsing the `mpg` dataset:\n1.  Create a boxplot of `hwy` (highway MPG) grouped by `class`.\n2.  Fill the boxes based on `drv` (drive train). Use `position = position_dodge(preserve = \"single\")` if boxes overlap too much.\n3.  Customize the color palette for `drv` using `scale_fill_brewer(palette = \"Set2\")`.\n4.  Add a title: \"Highway MPG Distribution by Class and Drive Train\".\n5.  Modify",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}